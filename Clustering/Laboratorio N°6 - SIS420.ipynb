{"cells":[{"cell_type":"markdown","metadata":{"id":"M2B8dH345C5e"},"source":["**Laboratorio N°6 - SIS420**\n","\n","**Introducción.**\n","\n","En este cuadernillo, para este laboratorio, nos enfocaremos en el aprendizaje no supervisado, por lo que usaremos el algoritmo *K-Means* para aplicar clustering a un conjunto de datos, de forma que así asignaremos etiquetas a los datos.\n","\n","**Objetivo.**\n","\n","Usar el algoritmo K-Means para proporcionar etiquetas detro de un conjunto de datos."]},{"cell_type":"markdown","metadata":{"id":"aNan3X3GNTSw"},"source":["**Declaración de las Librerías.** Primeramente, es necesario declarar cada una de las librerías a usar, así nos enfocaremos cómodamente en el algoritmo."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3641,"status":"ok","timestamp":1715658040345,"user":{"displayName":"Gabriel Aparicio LLanquipacha","userId":"17636720884960682861"},"user_tz":240},"id":"3mwUvY1-NSy_","outputId":"882d2b88-b233-48e3-f7f2-ae92bac7a2e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from sklearn.datasets import make_blobs\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.metrics import silhouette_score\n","import pandas as pd\n","import torch\n","from torch import optim\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import torchvision.datasets as datasets\n","from tqdm import tqdm\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%matplotlib inline"]},{"cell_type":"markdown","source":["# **Algoritmo K-means-**"],"metadata":{"id":"AAlsvbJkHOyG"}},{"cell_type":"markdown","source":["**Funciones para carga y procesamiento del dataset.**"],"metadata":{"id":"l2E7wAIQME11"}},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715658040345,"user":{"displayName":"Gabriel Aparicio LLanquipacha","userId":"17636720884960682861"},"user_tz":240},"id":"jI2XNQw4XfZr"},"outputs":[],"source":["def cargarDataset(_dataset):\n","  # Función para cargar un conjunto de datos desde un archivo CSV.\n","  dataset = pd.read_csv(_dataset, sep=';', header=0, decimal=',')\n","  # Lee el archivo CSV especificado y carga los datos en un DataFrame de pandas.\n","  movimientos_dataset = dataset['moves'].apply(contar_movimientos).apply(pd.Series)\n","  # Aplica una función \"contar_movimientos\" a la columna 'moves' y expande los resultados en nuevas columnas.\n","  dataset = dataset.join(movimientos_dataset.fillna(0))\n","  # Combina el DataFrame original con el DataFrame de los movimientos, rellenando los valores nulos con ceros.\n","  dataset.drop('moves', axis=1, inplace=True)\n","  # Elimina la columna 'moves' del DataFrame original.\n","  datos = {}\n","  # Inicializa un diccionario para almacenar los datos categóricos únicos.\n","  columnas = dataset.columns[dataset.dtypes == 'object'].tolist()\n","  # Obtiene una lista de columnas que contienen tipos de datos 'object'.\n","  for columna in columnas:\n","    # Itera sobre las columnas cuyos datos son de tipo 'object'.\n","    datos[columna] = dataset[columna].drop_duplicates().values\n","    # Obtiene los valores únicos de cada columna y los almacena en el diccionario \"datos\".\n","  datos_num = {}\n","  # Inicializa un diccionario para almacenar los valores categóricos y sus correspondientes valores numéricos.\n","  for columna, valores in datos.items():\n","    # Itera sobre las columnas y sus valores únicos.\n","    indice_reemp = 0\n","    datos_num_col = {}\n","    # Inicializa un diccionario para almacenar los valores numéricos correspondientes a los valores categóricos.\n","    for valor in valores:\n","      # Itera sobre los valores únicos de la columna.\n","      if valor not in datos_num_col and not pd.isnull(valor):\n","        # Si el valor no está presente en el diccionario y no es nulo:\n","        datos_num_col[valor] = indice_reemp\n","        indice_reemp += 1\n","        # Asigna un valor numérico al valor categórico y actualiza el índice.\n","    if np.nan not in datos_num_col:\n","      datos_num_col[np.nan] = 0\n","      # Si no hay un valor numérico asignado para NaN, asigna 0.\n","    datos_num[columna] = datos_num_col\n","    # Asigna el diccionario de valores numéricos al diccionario principal.\n","  for columna, d_n in datos_num.items():\n","    # Itera sobre las columnas y sus diccionarios de valores numéricos.\n","    dataset[columna] = dataset[columna].replace(d_n)\n","    # Reemplaza los valores categóricos con sus equivalentes numéricos en el DataFrame.\n","  dataset = dataset.fillna(0)\n","  # Rellena los valores nulos en el DataFrame con ceros.\n","  return dataset\n","  # Devuelve el DataFrame procesado."]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715658040345,"user":{"displayName":"Gabriel Aparicio LLanquipacha","userId":"17636720884960682861"},"user_tz":240},"id":"oDzdEo76jx0S"},"outputs":[],"source":["def contar_movimientos(moves):\n","    # Función para contar los movimientos en una cadena de movimientos de ajedrez.\n","    movimientos = moves.split()\n","    # Divide la cadena de movimientos en una lista de movimientos individuales.\n","    conteo_movimientos = {}\n","    # Inicializa un diccionario para almacenar los movimientos contados.\n","    turno = 1\n","    jugador = 'W'\n","    # Inicializa variables para llevar el control del turno y del jugador.\n","    for movimiento in movimientos:\n","        # Itera sobre los movimientos en la lista.\n","        if turno > 64:\n","            break\n","            # Rompe el bucle si se alcanza el límite de 32 movimientos.\n","        clave = f\"{turno}{jugador}\"\n","        # Crea una clave única para identificar el movimiento por turno y jugador.\n","        if clave not in conteo_movimientos:\n","            conteo_movimientos[clave] = \"\"\n","            # Si la clave no existe en el diccionario, inicializa un nuevo espacio.\n","        conteo_movimientos[clave] += movimiento + \" \"\n","        # Añade el movimiento actual al registro correspondiente.\n","        if jugador == 'W':\n","            jugador = 'B'\n","        else:\n","            jugador = 'W'\n","            turno += 1\n","            # Cambia el jugador y actualiza el turno después de cada movimiento.\n","    return conteo_movimientos\n","    # Devuelve el diccionario de movimientos contados."]},{"cell_type":"markdown","source":["**Funciones para las respectivas gráficas.**"],"metadata":{"id":"7fvCiYvlMLWw"}},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715658040345,"user":{"displayName":"Gabriel Aparicio LLanquipacha","userId":"17636720884960682861"},"user_tz":240},"id":"pGvstLTrYTDn"},"outputs":[],"source":["def graficar_fronteras_decision(clusterizador, X, caracteristicas=[8, 9], resolucion=1000, mostrar_centroides=True):\n","    # Función para graficar las fronteras de decisión de un clusterizador dado y los datos de entrada.\n","    X_vis = X[:, caracteristicas]\n","    # Selecciona las características específicas para la visualización.\n","    minimos = X_vis.min(axis=0) - 1\n","    maximos = X_vis.max(axis=0) + 1\n","    # Calcula los límites para la gráfica.\n","    xx, yy = np.meshgrid(np.linspace(minimos[0], maximos[0], resolucion),\n","                         np.linspace(minimos[1], maximos[1], resolucion))\n","    # Crea una malla de puntos para la visualización.\n","    malla = np.c_[xx.ravel(), yy.ravel()]\n","    malla_completa = np.zeros((len(malla), clusterizador.n_features_in_))\n","    malla_completa[:, caracteristicas] = malla\n","    # Prepara la malla completa para la predicción.\n","    Z = clusterizador.predict(malla_completa)\n","    Z = Z.reshape(xx.shape)\n","    # Realiza la predicción sobre la malla.\n","    plt.contourf(xx, yy, Z, alpha=0.5, cmap='Pastel2')\n","    plt.contour(xx, yy, Z, linewidths=1, colors='k')\n","    # Grafica las fronteras de decisión.\n","    plt.scatter(X_vis[:, 0], X_vis[:, 1], c=clusterizador.labels_, s=1)\n","    # Grafica los puntos de datos.\n","    graficar_datos(X)\n","    # Llama a la función para graficar los datos originales.\n","    if mostrar_centroides:\n","        graficar_centroides(clusterizador.cluster_centers_[:, caracteristicas])\n","        # Si se especifica, grafica los centroides de los clusters.\n","def graficar_centroides(centroides, color_circulo='w', color_cruz='k'):\n","    # Función para graficar los centroides de los clusters.\n","    plt.scatter(centroides[:, 0], centroides[:, 1],\n","                marker='o', s=10, linewidths=8,\n","                color=color_circulo, zorder=10, alpha=0.9)\n","    plt.scatter(centroides[:, 0], centroides[:, 1],\n","                marker='x', s=2, linewidths=10,\n","                color=color_cruz, zorder=11, alpha=1)\n","    # Grafica los centroides con círculos y cruces.\n","def graficar_datos(X):\n","    # Función para graficar los datos originales.\n","    plt.plot(X[:, 8], X[:, 9], 'k.', markersize=2)\n","    # Grafica los datos en el espacio de características especificado.\n","def graficar_clusters(X, y=None):\n","    # Función para graficar los clusters.\n","    plt.scatter(X[:, 8], X[:, 9], c=y, s=1)\n","    plt.xlabel(\"$x_1$\", fontsize=14)\n","    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n","    # Grafica los clusters con colores específicos (si se proporcionan) y etiqueta los ejes."]},{"cell_type":"markdown","source":["**Función para encontrar el mejor número posible de grupos.** La puntuación de Silhouette se utiliza como medida de la calidad de los clusters, donde valores más altos indican una mejor separación entre los clusters."],"metadata":{"id":"rgrP1roZMSzI"}},{"cell_type":"code","source":["def encontrar_numero_optimo_grupos(X):\n","    # Función para encontrar el número óptimo de grupos utilizando el método de Silhouette.\n","    kmeans_por_k = [KMeans(n_clusters=k, random_state=42).fit(X) for k in range(1, 10)]\n","    # Entrena modelos KMeans con diferentes números de clusters.\n","    puntuaciones_silhouette = [silhouette_score(X, modelo.labels_) for modelo in kmeans_por_k[1:]]\n","    # Calcula la puntuación de Silhouette para cada modelo.\n","    k_optimo = np.argmax(puntuaciones_silhouette) + 2\n","    # Encuentra el número óptimo de clusters basado en la puntuación de Silhouette.\n","    return k_optimo\n","    # Devuelve el número óptimo de clusters encontrado."],"metadata":{"id":"mC11nsgw0MbN","executionInfo":{"status":"ok","timestamp":1715658040345,"user_tz":240,"elapsed":4,"user":{"displayName":"Gabriel Aparicio LLanquipacha","userId":"17636720884960682861"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["*Este bloque de código carga el conjunto de datos, determina el número óptimo de clusters, aplica el algoritmo KMeans para encontrar los clusters óptimos, grafica los datos originales con los clusters encontrados y muestra las gráficas. Finalmente, asigna las etiquetas de los clusters al conjunto de datos para su posterior análisis.*"],"metadata":{"id":"HgpHHQonMcEE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7e6W_M3gLT-","collapsed":true},"outputs":[],"source":["dataset = cargarDataset('/content/gdrive/MyDrive/SIS420/Laboratorio-N6_-_SIS420/Dataset/games.csv')\n","# Carga el conjunto de datos desde el archivo 'games.csv' utilizando la función 'cargarDataset'.\n","k_optimo = encontrar_numero_optimo_grupos(dataset)\n","# Encuentra el número óptimo de grupos en el conjunto de datos utilizando la función 'encontrar_numero_optimo_grupos'.\n","kmeans_optimo = KMeans(n_clusters=k_optimo, n_init=10, random_state=42)\n","# Inicializa un objeto KMeans con el número óptimo de grupos encontrado y otros parámetros.\n","kmeans_optimo.fit(dataset)\n","# Aplica el algoritmo KMeans al conjunto de datos para encontrar los grupos óptimos.\n","graficar_clusters(dataset.values)\n","# Grafica los datos originales con los clusters encontrados.\n","graficar_fronteras_decision(kmeans_optimo, dataset.values)\n","# Grafica las fronteras de decisión para los clusters encontrados.\n","plt.show()\n","# Muestra las gráficas.\n","y = kmeans_optimo.labels_\n","# Obtiene las etiquetas de los clusters asignadas por KMeans.\n","dataset['labels'] = y\n","# Añade las etiquetas de los clusters al conjunto de datos."]},{"cell_type":"markdown","source":["# **Prueba del Dataset con sus respectivas etiquetas.**"],"metadata":{"id":"wFjgd5A4G5xu"}},{"cell_type":"markdown","source":["*Para este cometido se usará la red neuronal del Laboratorio N°5, por lo que los pasos no requieren estar explicados.*"],"metadata":{"id":"KHizca_kHCjG"}},{"cell_type":"code","source":["class RedNeuronalMLS(nn.Module):\n","    def __init__(self, ce, ne):\n","        super(RedNeuronalMLS, self).__init__()\n","        co = int(np.sqrt(ce * ne))\n","        self.capa_oculta = nn.Linear(ce, co)\n","        self.capa_salida = nn.Linear(co, ne)\n","    def forward(self, x):\n","        x = self.capa_oculta(x)\n","        x = F.sigmoid(x)\n","        x = self.capa_salida(x)\n","        return x"],"metadata":{"id":"iPeVR5xE_YPy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calcularPrecisionModel(loader, modelo):\n","  num_correct = 0\n","  num_samples = 0\n","  modelo.eval()\n","  predicciones = []\n","  with torch.no_grad():\n","      for x, y in loader:\n","          x = x.to(device=dispositivo)\n","          y = y.to(device=dispositivo)\n","          x = x.reshape(x.shape[0], -1)\n","          scores = modelo(x)\n","          _, predictions = scores.max(1)\n","          predicciones.append(predictions)\n","          num_correct += (predictions == y).sum()\n","          num_samples += predictions.size(0)\n","  modelo.train()\n","  return num_correct/num_samples, predicciones"],"metadata":{"id":"5rhVd3SMAmjw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calcularPrecisionModel(loader, modelo):\n","  num_correct = 0\n","  num_samples = 0\n","  modelo.eval()\n","  predicciones = []\n","  with torch.no_grad():\n","      for x, y in loader:\n","          x = x.to(device=dispositivo)\n","          y = y.to(device=dispositivo)\n","          x = x.reshape(x.shape[0], -1)\n","          scores = modelo(x)\n","          _, predictions = scores.max(1)\n","          predicciones.append(predictions)\n","          num_correct += (predictions == y).sum()\n","          num_samples += predictions.size(0)\n","  modelo.train()\n","  return num_correct/num_samples, predicciones"],"metadata":{"id":"XlLVw3b7BKnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dispositivo = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=99)\n","X_train, y_train = train_set.iloc[:, :-1], train_set.iloc[:, -1]\n","X_test, y_test = test_set.iloc[:, :-1], test_set.iloc[:, -1]\n","X_train = np.concatenate([np.ones((X_train.shape[0], 1)), X_train], axis=1)\n","X_test = np.concatenate([np.ones((X_test.shape[0], 1)), X_test], axis=1)\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n","y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.int64)\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"],"metadata":{"id":"L5hWypbZApeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["caracteristicas_entrada = X_train.shape[1]\n","numero_etiquetas = len(np.unique(y_train))\n","tasa_aprendizaje = 0.001\n","tamaño_lote = 100000\n","numero_iteraciones = 100\n","train_loader = DataLoader(train_dataset, batch_size=tamaño_lote, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=tamaño_lote, shuffle=False)"],"metadata":{"id":"_s3KHCV4A-Wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelo = RedNeuronalMLS(caracteristicas_entrada, numero_etiquetas).to(dispositivo)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(modelo.parameters(), lr=tasa_aprendizaje)\n","for epoch in range(numero_iteraciones):\n","    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n","        data = data.to(device=dispositivo)\n","        targets = targets.to(device=dispositivo)\n","        data = data.reshape(data.shape[0], -1)\n","        scores = modelo(data)\n","        loss = criterion(scores, targets)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()"],"metadata":{"id":"b6zsBGsfBEM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_train, pred_train = calcularPrecisionModel(train_loader, modelo)\n","p_test, pred_test = calcularPrecisionModel(test_loader, modelo)\n","print(f\"Presición en el dataset de entrenamiento: {p_train*100:.2f}\")\n","print(f\"Presición en el dataset de prueba: {p_test*100:.2f}\")"],"metadata":{"id":"wjVBxtGBBGv7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9DcexXNAmxEynnJJvqMbR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}